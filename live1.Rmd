---
title: "*Bayes Lives*"
subtitle: |
    Série de *Lives* de Introdução às Bases da Estatística Bayesiana \
    *Live* 1/6: 
      Apresentando a Estatística Bayesiana
author: "Marcelo Ventura"
date: "16/03/2020"
output: 
  beamer_presentation:
    # keep_tex: yes
    toc: true
    slide_level: 2
    theme: Berkeley
    colortheme: sidebartab
    fonttheme: structurebold
    highlight: haddock
header-includes:
  - \usepackage{enumitem}
  - \usepackage{tikzsymbols}
  - \setlistdepth{20}
  - \renewlist{itemize}{itemize}{20}
  - \renewlist{enumerate}{enumerate}{20}
  - \setlist[itemize]{label=$\cdot$}
  - \setlist[itemize,1]{label=*}
  - \setlist[itemize,2]{label=\textbullet}
  - \setlist[itemize,3]{label=--}
  - \setlist[itemize,4]{label=$\cdot$}
---

```{r setup, include=FALSE}
options(
  omitlatexcom = TRUE
)
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE, 
  cache = TRUE
)
knitr::knit_hooks$set(
  mysize = function(before, options, envir) {
    if (before) {
      return(options$size)
    } else {
      return("\\normalsize")
    }
  }
)
knitr::opts_chunk$set(
  mysize = TRUE, 
  size = "\\tiny"
)
library(tidyverse)
library(kableExtra)
library(rjags)
library(runjags)
library(R2jags)
library(MCMCvis)
`%!in%` <- negate(`%in%`)
runjags.options(
  mode.continuous = T
)
```

# Apresentação

## Muito prazer! Meu nome é Marcelo.

### Formação

- Doutorado em Probabilidade e Estatística, IME/USP, 2005
- Mestrado em Probabilidade e Estatística, IMECC/Unicamp, 2001
- Bacharelado em Estatística, ENCE/IBGE, 1998
- Técnico em Processamento de Dados, FB/RJ, 1992


### Afiliações

- Professor Doutor na EACH/USP
- Admin na Comunidade *R Brasil* no Telegram
  - <https://t.me/rbrasiloficial>
- Conselheiro do CONRE-3/SP



## Objetivos desta Série de *Lives*

É dar uma visão panorâmica daquilo que dá a base, que dá o fundamento à 
Estatística Bayesiana, mas sem se pretender ser um tutorial de uso e nem um 
curso teórico, pois não disporíamos de tempo o suficiente para nenhum dos dois.

- O tutorial fica para a próxima série de *lives*. $\Winkey$

- O repositório deste material está em <https://github.com/zyxdef/BayesLives>



# Exemplos Guias

## Exemplos para Todos os Gostos

### Exemplos serão Úteis para

Além de 

- audiência conseguir se conectar melhor com as preocupações de um análise de
  dados
- apresentar graus crescentes de complexidade de cenários de análise de dados
- dar concretude aos conceitos mais abstratos que vou apresentar nas próximas
  *lives*
  
Na última *live*
  
- vou retormar esses exemplos e analisar usando todos os conceitos e ferramentas
  computacionais que vamos ter visto



## Exemplos para Todos os Gostos

### Porquê vou Começar por Exemplos?

Para cada exemplo, apresentaremos uma situação em que é preciso apresentar
informações sobre o contexto da situação



## Exemplos para Todos os Gostos

### Porquê as Informações sobre o Contexto são Necessárias?

- toda análise é estritamente condicionada no contexto de onde seus dados vieram
- quais conceitos e definições devem ser usados?
- quais pressuposições podem ser assumidas a respeito 
  - do que observamos?
  - do que *não* observamos?
- qual é a natureza dos dados a serem trabalhados?
  - importa como, quando e em que ordem eles foram coletados?
  - se sim, quais são as respostas a essas perguntas?
- não se faz análise em um vácuo de contexto (viu, ML e IA?)



## O que vou Apresentar em Cada Exemplo

### Para cada Exemplo, Apresentaremos uma Situação com

- contexto
- necessidade de informação
- dados observados
- pelo menos um método Bayesiano que pode ser empregado no problema
- conclusão obtida para a necessidade de informação com a aplicação 
  desse método nesses dados



## O que Posso Apresentar em Cada Exemplo

### Contexto

- com qual(is) fenômeno(s) e seus aspectos lidaremos

### Necessidade de Informação

- quais aspectos não observados se deseja conhecer?
  - parâmetros? variáveis latentes?
- há outros aspectos (conhecidos ou desconhecidos) que não sejam de nosso
  interesse direto, mas que interfiram em nossa capacidade de compreender os
  aspectos de interesse?
  - variáveis de controle/cofatores? variáveis omitidas?
- quem precisa dessa informação?
- de qual informação essa pessoa precisa?
- qual o nível de detalhamento é necessário?



## O que Posso Apresentar em Cada Exemplo

### Dados Observados

- apresentados parcial ou totalmente, em forma tabular 
- discussão sobre as variáveis
- indico a fonte dos dados, para fins de reprodutibilidade
  
### Como Podemos Lidar com o Problema

- nome de, pelo menos, um método bayesiano compatível com o contexto, a
  necessidade de informação e a estrutura do conjunto de dados

### Conclusão Obtida para a Necessidade de Informação com a Aplicação desse Método nesses Dados

- análise no R da estimação via MCMC com o software JAGS


## Critérios para a Escolha dos Exemplos

- serão exemplos vindos de áreas distintas
  - marketing digital
  - controle de qualidade
  - precificação
- os métodos cobrirão tipos diferentes de dados
  - respostas dummy, contagem e contínua
  - regressoras categóricas e quantitativas
- os modelos terão grau crescente de complexidade 
  - modelos *single level*
  - modelos hierárquicos *multi-level*



# Exemplo 1: nível *very easy*

## Contexto e Necessidade de Informação

### Contexto

- teste A/B referente a conversões do acesso em venda (i.e., o usuário clicar no
  botão de venda) na *landing page* do *site* de uma empresa

### Necessidade de Informação

- mudar um aspecto específico da *landing page* modifica a sua chance de
  conversão?
  - se sim, qual é a direção dessa mudança? Aumenta ou diminui a chance?
- métrica de performance
  - conversão: quantos usuários clicaram no botão de contratação do serviço



## Dados Observados

Conjunto de dados do Kaggle

```{r carrega_dataset1}
if (file.exists("dataset1.Rds")) {
  dataset1 <- read_rds("dataset1.Rds")
} else {
  dataset1 <- read_csv("conjuntos de dados/ab_data.csv")
  write_rds(dataset1, "dataset1.Rds")
}
```

- `r ncol(dataset1)` colunas e `r nrow(dataset1)` linhas
- <https://www.kaggle.com/zhangluyuan/ab-testing>

```{r imprime_dataset1}
head(dataset1) %>% 
  kable("pandoc")
```



## Dados Observados

### Variáveis que não Usaremos

- `user_id`: identificação do usuário que acessou a *landing page*
- `timestamp`: data e hora do acesso à *landing page*
  - em princípio, não deveria ter influência na conversão, mas podemos avaliar
    isso de forma descritiva sem precisar de modelagem ou teste
- `group`: grupo em que o acesso foi alocado
  - aleatorizado no momento do acesso à *landing page*
  - `control` *vs* `treatment`
  - em princípio, é para ser a mesmo coisa que a `landing_page` a seguir, mas 
    veremos que não é



## Dados Observados

### Variáveis: quais Usaremos

- `landing_page`: qual versão da página foi acessada
  - variável independente nominal
  - `old_page` *vs* `new_page`
- `converted`: conversão em venda 
  - variável resposta binária
  - 0 == não *vs* 1 == sim



## Eu Posso Querer

- saber se a nova versão da *landing page* aumenta a probabilidade de conversão
  - se sim, aumenta em quanto essa probabilidade?
- saber se a probabilidade de conversão é igual nos dois grupos
  - se for diferente, qual *landing page* tem maior probabilidade de conversão?
  - qual é a diferença entre essas probabilidades?
- só uma estimativa da diferença entre as probabilidade de conversão em função 
  da diferença entre as versões nova e a antiga da *landing page*, sem nenhuma 
  direção preferencial
  - qual é o valor mais provável dessa diferença?
  - há mais outra forma de estimar essa diferença?
  - qual é a faixa de valores mais provável dessa diferença?



## Um Método que Pode ser Empregado no Problema

Para uma variável resposta binária e uma regressora nominal, poderíamos usar uma
regressão logística, cuja parametrização pode ser escolhida em função das 
várias formas diferentes de com que posso formular a questão de interesse.

Mas, mais simples que isso, podemos comparar diretamente as probabilidades de
conversão das duas *landing pages* ou estimar diretamente sua diferença.



## *Caveat Emptor*

Mas cuidado: parece que `group` e `landing_page` são a mesma coisa, mas não são. 

Separando os respondentes em dois grupos, veremos que...

```{r tab_dataset1}
dataset1 %>% 
  group_by(user_id) %>% 
  mutate(acessos = n()) %>% 
  ungroup() ->
  dataset1
dataset1 %>% 
  filter(acessos == 1) %>% 
  with(table(group, landing_page)) %>% 
  kable("pandoc")
dataset1 %>% 
  filter(acessos > 1) %>% 
  with(table(group, landing_page)) %>% 
  kable("pandoc")
```

... essas variáveis tem significados levemente diferentes nos dois grupos.



## *Caveat Emptor*

### O que Farei Então?

- Precisaríamos ter acesso ao planejamento desse experimento para termos mais
  informação sobre a diferença entre esses grupos e essas variáveis.

- Como essa diferença não é documentada no conjunto de dados, então, para os 
  fins da análise deste exemplo, eliminarei os dados dos usuários que acessaram
  mais de uma vez o site e que, por esse motivo, tiveram contato com ambas as
  versões da *landing page*, que é um fator complicador desnecessário para este
  exemplo, que pretende ser de nível *very easy*.

```{r elimina_acessos_duplos_dataset1}
dataset1 %>% 
  filter(acessos == 1) %>% 
  select(-acessos, -group) ->
  dataset1
```



## Dados que Serão Usados

Após eliminar as observações que estavam relacionadas aos usuários com mais de 
um acessos à *landing page*, ficamos com apenas `r nrow(dataset1)` observações 
de acessos únicos e, nesse caso, também não precisamos da variável `group`, 
ficando apenas com a regressora binária `landing_page`.

```{r dataset1_limpo}
dataset1 %>% 
  with(
    table(
      landing_page,
      converted
    )
  ) %>% 
  kable(
    "pandoc", 
    format.args = 
      list(
        big.mark = ".", 
        decimal.mark = ","
      )
  )
```



<!-- ## Antes de ter Acesso aos Dados, o que Posso Pensar das Probabilidades de Conversão das duas versões de *Landing Page*? -->

<!-- ```{r modelo1_prioris} -->
<!-- ggplot(aes(x = 0:1)) + -->
<!--   geom_hline(yintercept = 1) -->

<!-- ``` -->




## O que esses dados revelam?

```{r roda_exemplo_1, include=FALSE, cache=FALSE}
if (file.exists("saida1_runjags.Rds")) {
  saida1_runjags <- read_rds("saida1_runjags.Rds")
} else {
  modelo1 <- 
"
# modelo para comparação das probabilidades de duas binomiais
# já estou escrevendo um código BUGS com mais de uma parametrização
model {
  # modelo observado
      converted.new_page ~ dbin(p.new_page, N.new_page)
      converted.old_page ~ dbin(p.old_page, N.old_page)
  # modelo latente com uma possível parametrização
  # usando prioris vagas
      p.old_page ~ dbeta(1, 1)
      p.new_page ~ dbeta(1, 1)
      delta.p <- p.new_page - p.old_page
  # outras possíveis parametrizações de interesse
      pct.old_page <- 100 * p.old_page
      pct.new_page <- 100 * p.new_page
      delta.pct <- pct.new_page - pct.old_page
      probab.delta.p.negativo <- 100 * (pct.new_page < pct.old_page)
}"

  saida1_runjags <- 
    runjags::run.jags(
      model = modelo1,
      data = 
        dataset1 %>% 
        group_by(landing_page) %>% 
        summarise(
          converted = sum(converted),
          N = n()
        ) %>% 
        with(
          list(
            converted.new_page = converted[1],
            N.new_page = N[1],
            converted.old_page = converted[2],
            N.old_page = N[2]
          )
        ), 
      inits = 
        list(
          list(p.old_page = .3, delta.logit.p =  0),
          list(p.old_page = .5, delta.logit.p = -100),
          list(p.old_page = .7, delta.logit.p = +100)
        ), 
      n.chains = 3, 
      monitor =
        c(
          "p.old_page", 
          "p.new_page", 
          "delta.logit.p", 
          "delta.p",
          "pct.old_page",
          "pct.new_page",
          "delta.pct",
          "probab.delta.p.negativo"
        ),
      sample = 1e5
    )
  write_rds(saida1_runjags, "saida1_runjags.Rds")
}
```

<!-- ```{r imprime_modelo_1} -->
<!-- saida1_runjags$model -->
<!-- ``` -->

<!-- > "Oh, mas o que é isso, Marcelo?!? Não estou entendendo nada!!! Eu tenho medo!" -->

<!-- Relaxa, que até a 6^a^ *live* vai fazer mais sentido -->


```{r imprime_exemplo_1}
saida1_runjags
```



## O que esses dados revelam?

```{r graficos1a, fig.height=3, message=FALSE}
saida1_runjags %>% 
  runjags:::plot.runjags(vars = "pct.old_page", plot.type = c("density")
                         )
saida1_runjags %>% 
  runjags:::plot.runjags(vars = "pct.new_page", plot.type = c("density"))
```



## O que esses dados revelam?

```{r graficos1b}
saida1_runjags %>% plot(vars = "delta.pct")
```



## O que esses dados revelam?

### Sobre `probab.delta.p.negativo` e `delta.pct`

- estimamos que a probabilidade a posteriori de a nova *landing page* ter
  conversão *menor* do que a da velha seja de 
 `r saida1_runjags$summaries["probab.delta.p.negativo", "Mean"] %>% round(2)`% 
- estimamos que a diferença entre as probabilidades de conversão entre as 
  páginas nova e velha deve ser ao redor de 
  `r saida1_runjags$summaries["delta.pct", "Mean"] %>% round(2)`%.
  <!-- - vai depender do contexto se isso é uma diferença fenomenologicamente -->
  <!--   significativa ou não -->
- com 90% de probabilidade, a diferença entre as probabilidades estará no
  intervalo [`r saida1_runjags$summaries["delta.pct", "Lower95"] %>% round(2)`%, 
  `r saida1_runjags$summaries["delta.pct", "Upper95"] %>% round(2)`%], com 5% de
  probabilidade abaixo e 5% acima desse intervalo.
  
### Sobre `pct.old_page` e `pct.new_page`

- é possível estimar as probabilidades de conversão na página antiga e nova por 
`r saida1_runjags$summaries["pct.old_page", "Mean"] %>% round(2)`% e 
`r saida1_runjags$summaries["pct.new_page", "Mean"] %>% round(2)`%
respectivamente.



# Exemplo 2: nível *easy*

## Contexto e Necessidade de Informação

### Contexto

  - avaliar a intensidade do processo de rompimento de fibra de lã com o mesmo 
    comprimento em um tear em função do tipo da lã e da tensão a que a fibra 
    fica submetida

### Necessidade de Informação

  - há diferença sistemática no número de ocorrências de rompimento entre as 
    duas fibras?
  - é razoável esperar que, à medida que a tensão cresce, os rompimentos também
    aumentem; isso de fato ocorre?
  - o aumento de rompimento em função do aumento de tensão ocorre da mesma forma 
    nos dois tipos de lã?



## Dados Observados

- fonte: `help(warpbreaks)`

```{r dados_exemplo_2, include=FALSE}
warpbreaks %>% 
  head() %>% 
  kable("pandoc", format.args = list())
```



## Dados Observados

### Variáveis

- `breaks`: número de quebra nas fibras
  - variável resposta discreta 
    - dado de contagem
- `wool`: tipo da fibra
  - variável regressora nominal
  - `À` *vs* `B`
- `tension`: tensão a que a fibra estava submetida
  - variável regressora ordinal
  - `L` = *low*, `M` = *medium*, `H` = *high*
  - se a tensão tivesse sido registrada em Pascals (Pa, unidade SI para tensão),
    seria um modelo mais rico, com possibilidade de não linearidade no 
    relacionamento com a variável dependente



## Eu Posso Querer Saber

- se há diferença de ruptura entre os dois tipos de lã
  - se sim, qual tipo de lã tem menor ruptura?
- se, de fato, a ruptura aumenta conforme a tensão aumenta
  - se sim, aumenta quanto entre cada nível?
- etc.  



## Um Método que Pode ser Empregado no Problema

- uma regressoras nominal e uma ordinal
- variável resposta de contagem: modelada por uma distribuição Poisson com um
  parâmetro $\lambda$ de intensidade em função das regressoras
- podemos usar o modelo de regressão Poisson

## Um Método que Pode ser Empregado no Problema

### *Crash Course* em Regressão Poisson: 

\small

- o modelo de regressão Poisson consistem em 
  - $Y_i \sim Poisson(\lambda_i)$ 
    com $\log(\lambda_i) = \alpha + \beta_1 x_{1i} + \ldots + \beta_k x_{ki}$ 
    ou, equivalentemente, 
    $\lambda_i = e^{\alpha} e^{\beta_1 x_{1i}} \cdots e^{\beta_k x_{ki}}$,
    i.e., cada termo $e^{\beta_j x_{ji}}$ é um termos multiplicativo em cima de 
    $e^\alpha$
  - como nossas regressoras são categóricas, elas serão codificadas como
    variáveis *dummies*, de modo que 
    - $x_{ji}$ será ou 0 ou 1, 
    - $\beta_j x_{ji}$ será ou 0 ou $\beta_j$
    - $e^{\beta_j x_{ji}}$ será ou 1 ou $e^{\beta_j}$
    - se $\beta_j > 0$, então $e^{\beta_j} > 1$ e aumentará $e^\alpha$
    - se $\beta_j < 0$, então $e^{\beta_j} < 1$ e diminuirá $e^\alpha$
- com Estatística Clássica, é um modelo linear generalizado, estimado por
  maximização de verossimilhança
- com Estatística Bayesiana, encontramos as distribuições a posteriori dos 
  parâmetros via MCMC

\normalsize

## Modelo que Será Usado

```{r}
MCMCpack::MCMCpoisson(breaks ~ wool + tension, warpbreaks) %>% 
  summary()
MCMCpack::MCMCpoisson(breaks ~ wool * tension, warpbreaks) %>% 
  summary()
```


## O que esses Dados Revelam?

```{r roda_exemplo_2, include=FALSE, cache=FALSE}
if (file.exists("saida2_runjags.Rds")) {
  saida2_runjags <- read_rds("saida2_runjags.Rds")
} else {
  modelo2 <- 
"
# modelo para regressão Poisson
# parametrização: 
#   alpha_A_L é o parâmetro de tension == L e wool == A
#   beta_A_B é o efeito diferencial entre wool == A e wool == B
#   gamma_L_M é o efeito diferencial de tension == L para tension == M
#   gamma_M_H é o efeito diferencial de tension == M para tension == H
model {
  for (i in 1:N) {
    # modelo observado
    breaks[i] ~ dpois(lambda[i])
    log(lambda[i]) <- 
      alpha_A_L + 
      beta_A_B * wool_B[i] +
      gamma_L_M * tension_M[i] +
      (gamma_L_M + gamma_M_H) * tension_H[i]
  }
# usando prioris vagas
  alpha_A_L ~ dnorm(0, 1e2)
  beta_A_B ~ dnorm(0, 1e2)
  gamma_L_M ~ dnorm(0, 1e2)
  gamma_M_H ~ dnorm(0, 1e2)
# valores de interesse
  lambda_A_L <- exp(alpha_A_L                                   )
  lambda_A_M <- exp(alpha_A_L            + gamma_L_M            )
  lambda_A_H <- exp(alpha_A_L            + gamma_L_M + gamma_M_H)
  lambda_B_L <- exp(alpha_A_L + beta_A_B                        )
  lambda_B_M <- exp(alpha_A_L + beta_A_B + gamma_L_M            )
  lambda_B_H <- exp(alpha_A_L + beta_A_B + gamma_L_M + gamma_M_H)
}"

  saida2_runjags <- 
    runjags::run.jags(
      model = modelo2,
      data = 
        with(
          warpbreaks,
          list(
            N = nrow(warpbreaks),
            breaks = breaks,
            wool_B = (wool == "B") %>% as.integer(),
            tension_M = (tension == "M") %>% as.integer(),
            tension_H = (tension == "H") %>% as.integer()
          )
        ),
      inits = 
        list(
          list(alpha_A_L =   0, beta_A_B = +10, gamma_L_M = -10, gamma_M_H =   0),
          list(alpha_A_L = +10, beta_A_B =   0, gamma_L_M = -10, gamma_M_H = +10),
          list(alpha_A_L = -10, beta_A_B = -10, gamma_L_M =   0, gamma_M_H = +10)
        ),
      n.chains = 3, 
      monitor =
        c(
          "alpha_A_L",
          "beta_A_B",
          "gamma_L_M",
          "gamma_M_H",
          "lambda_A_L",
          "lambda_A_M",
          "lambda_A_H",
          "lambda_B_L",
          "lambda_B_M",
          "lambda_B_H"
        ),
      sample = 1e5, 
      modules = "glm on"
    )
  write_rds(saida2_runjags, "saida2_runjags.Rds")
}
```

<!-- ```{r imprime_modelo_2} -->
<!-- saida2_runjags$model -->
<!-- ``` -->



```{r imprime_exemplo_2}
saida2_runjags
```



## O que esses Dados Revelam?

```{r graficos2a, fig.height=3, message=FALSE}
saida2_runjags %>% 
  plot(vars = "alpha_A_L", plot.type = c("density"))
saida2_runjags %>% 
  plot(vars = "lambda_A_L", plot.type = c("density"))
```



## O que esses Dados Revelam?

```{r graficos2b, fig.height=3, message=FALSE}
saida2_runjags %>% 
  plot(vars = "beta_A_B", plot.type = c("density"))
saida2_runjags %>% 
  plot(vars = "lambda_B_L", plot.type = c("density"))
```



## O que esses Dados Revelam?

```{r graficos2c, fig.height=3, message=FALSE}
saida2_runjags %>% 
  runjags:::plot.runjags(vars = "gamma_L_M", plot.type = c("density"))
saida2_runjags %>% 
  runjags:::plot.runjags(vars = "gamma_M_H", plot.type = c("density"))
```

## Rodando com outro pacote, obteríamos

```{r saida2_MCMCpack}
if (file.exists("saida2_MCMCpack.Rds")) {
  saida2_MCMCpack <- read_rds("saida2_MCMCpack.Rds")
} else {
  saida2_MCMCpack <- 
    MCMCpack::MCMCpoisson(
      breaks ~ wool + tension, 
      data = warpbreaks, 
      mcmc = 1e5
    )
  write_rds(saida2_MCMCpack, "saida2_MCMCpack.Rds")
}
saida2_MCMCpack %>% summary()
```




## O que esses Dados Revelam?

- sobre `alpha_A_L`
  - tomando `wool==A` e `tension==L` como classe de referência, poderemos 
    esperar $E(Y_{AL}) = e^{\alpha_{AL}}$, cuja média a posteriori foi
    `r saida2_runjags$summaries["lambda_A_L", "Mean"] %>% round(2)` rompimentos
    por fio de lã
- sobre `beta_A_B`
  - dá o efeito diferencial de passar de `wool == A` para `wool == B`
  - como `beta_A_B` concentra quase toda sua probabilidade a posterior acima de
    zero, então $E(Y_{B\cdot}) > E(Y_{A\cdot})$
- sobre `gamma_L_M`
  - dá o efeito diferencial de passar de `tension == L` para `tension == M`
  - como `gamma_L_M` concentra quase toda sua probabilidade a posterior acima de
    zero, então $E(Y_{\cdot M}) > E(Y_{\cdot L})$



## O que esses Dados Revelam?

- sobre `gamma_M_H`
  - dá o efeito diferencial de passar de `tension == M` para `tension == H`
  - surpreendentemente, ocorre um efeito protetor quando se traciona o fio de lã
    para a tensão `H`, pois o efeito diferencial `gamma_M_H` concentra quase
    toda a sua probabilidade a posteriori abaixo de zero, o que quer dizer que 
    - se você tensiona mais, era para romper mais, certo? errado: os dados
      apoiam a hipótese oposta
  - como `gamma_M_H` concentra quase toda sua probabilidade a posterior *abaixo*
    de zero, então $E(Y_{\cdot H})$ será *menor* que $E(Y_{\cdot M})$

## Péra! *Reality Check* em 3, 2, 1

Esse modelo faz sentido?  Tá batendo com os dados?

### Descritivas

```{r dataset2_descritivas1}
warpbreaks %>% 
  group_by(wool, tension) %>% 
  summarise(breaks = mean(breaks) %>% round(2)) %>% 
  pivot_wider(names_from = tension, values_from = breaks) %>% 
  kable("pandoc", format.args = list(decimal.mark = ","))
```

### Ajuste do Modelo

```{r dataset2_modelo1}
saida2_runjags$summaries[5:10, "Mean"] %>% 
  round(2) %>% 
  matrix(nrow = 2, dimnames = list(c("A", "B"), c("L", "M", "H"))) %>% 
  kable("pandoc", row.names = T)
```

## Péra! *Reality Check* em 3, 2, 1

Nope. Algo de errado não está certo!

- note que as rupturas em função da tensão têm comportamento diferentes para 
  `wool == A` e para `wool == B` 
- pode haver interação (sinergia ou antagonismo) entre os fatores `wool` e 
  `tension`
- como introduzir os termos de interação?
- como medir a adequação do modelo sem termos de interação aos dados?
- e a do modelo com termos de interação?
- como medir a diferença de ajuste entre esses modelo?
- tantas perguntas...
- veremos um pouco disso tudo na 6^a^ *live*



# Exemplo 3: nível *moderate*

## Contexto e Necessidade de Informação

### Contexto

- precificação de modelos de laptops
- fonte: <https://www.kaggle.com/ionaskel/laptop-prices>

### Necessidade de Informação

- quais fatores são mais influentes na definição de preço? 
  - Não o *custo* de fabricação, mas sim o *preço* que os consumidores estão
    dispostos a pagar
- é possível montar um modelo de precificação para um novo modelo de laptop em 
  termos das características que o modelo terá? qual seria uma faixa plausível 
  de valores para se propor?



## Dados Observados

```{r carrega_dataset3, cache=FALSE, include=FALSE, message=FALSE, warning=FALSE}
if (file.exists("dataset3.Rds")) {
  dataset3 <- read_rds("dataset3.Rds")
} else {
  dataset3 <- read_csv("conjuntos de dados/laptops.csv")
  dataset3 %>% 
    mutate(
      Resolution = ScreenResolution %>% str_extract("[0-9]*x[0-9]*"),
      Width_pixels = 
        Resolution %>% 
        str_extract("^[0-9]*") %>% 
        as.numeric(),
      Height_pixels = 
        Resolution %>%
        str_extract("[0-9]*$") %>% 
        as.numeric(),
      PPI = sqrt(Width_pixels^2 + Height_pixels^2)/Inches,
      Touchscreen = 
        ScreenResolution %>% 
        str_detect(fixed("Touchscreen")),
      FreqCPU = 
        Cpu %>% 
        str_extract(" [0-9]*\\.?[0-9]*GHz") %>% 
        str_replace(fixed("GHz"), "") %>% 
        str_squish() %>% 
        as.numeric(),
      FreqCPUUnit = 
        Cpu %>% 
        str_extract("[GM]Hz$"),
      CPUMaker = 
        Cpu %>% 
        str_extract("^[^ ]*"),
      GPUMaker = 
        Gpu %>% 
        str_extract("^[^ ]*"),
      WeightUnit = 
        Weight %>% 
        str_extract("[A-Za-z]*$"),
      WeightValue = 
        Weight %>% 
        str_extract("^[0-9.]*"),
      RamValue = 
        Ram %>% 
        str_extract("[0-9]*") %>% 
        as.numeric(),
      HDD = 
        Memory %>% 
        str_extract("[0-9]*[TG]B HDD"),
      HDDUnit = 
        HDD %>% 
        str_extract("[TG]B"),
      HDDValue = 
        HDD %>% 
        str_extract("[0-9]*") %>% 
        as.numeric() * 
        if_else(HDDUnit == "TB", 1000, 1),
      SSD = 
        Memory %>% 
        str_extract("[0-9]*[TG]B SSD"),
      SSDUnit = 
        SSD %>% 
        str_extract("[TG]B"),
      SSDValue = 
        SSD %>% 
        str_extract("[0-9]*") %>%
        as.numeric() *
        if_else(SSDUnit == "TB", 1000, 1),
      Flash =
        Memory %>% 
        str_extract("[0-9]*[TG]B Flash Storage"),
      FlashUnit = 
        Flash %>% 
        str_extract("[TG]B"),
      FlashValue = 
        Flash %>% 
        str_extract("[0-9]*") %>%
        as.numeric() *
        if_else(FlashUnit == "TB", 1000, 1)
     ) %>% 
    select(
      -X1,
      -Product,
      -ScreenResolution,
      -Cpu,
      -Ram,
      -Memory,
      -Gpu,
      -Weight,
      -WeightUnit,
      -Resolution,
      -Width_pixels,
      -Height_pixels,
      -FreqCPUUnit,
      -HDD,
      -HDDUnit,
      -SSD,
      -SSDUnit,
      -Flash,
      -FlashUnit
    ) %>%
    rename(
      Ram = RamValue,
      Weight = WeightValue,
      HDD = HDDValue,
      SSD = SSDValue,
      Flash = FlashValue
    ) %>%
    filter(CPUMaker != "Samsung" & GPUMaker != "ARM") %>% 
    mutate(
      HDD = replace_na(HDD, 0),
      SSD = replace_na(SSD, 0),
      Flash = replace_na(Flash, 0)
    ) %>% 
    mutate_if(is.character, as_factor) ->
    dataset3
  write_rds(dataset3, "dataset3.Rds")
}
```

<!-- ```{r dataset3_imprime} -->
<!-- dataset3 %>%  -->
<!--   head() %>%  -->
<!--   kable("pandoc") -->
<!-- ``` -->

```{r dataset3_summary, warning=FALSE}
dataset3 %>% 
  summary()
# map(dataset3, table)
```


## Um Método que Pode ser Empregado no Problema

- em Estatística Clássica, é um modelo de regressão linear com uma variável
  resposta contínua e várias regressoras
- em Estatística Bayesiano, é um modelo de regressão de nível único
  (*single-level*), pois existe modelo *multi-level*, que veremos no próximo
  exemplo

```{r ajusta3}
if (file.exists("saida3_MCMCregr.Rds")) {
  # saida3_MCMCregr <- read_rds("saida3_MCMCregr.Rds")
  saida3_runjags <- read_rds("saida3_runjags.Rds")
} else {
  # saida3_MCMCregr <-
  #   MCMCpack::MCMCregress(
  #     Price_euros ~
  #       Company +
  #       TypeName +
  #       Inches +
  #       OpSys +
  #       PPI +
  #       Touchscreen +
  #       FreqCPU +
  #       CPUMaker +
  #       GPUMaker +
  #       Weight +
  #       Ram +
  #       HDD +
  #       SSD +
  #       Flash,
  #     data = dataset3,
  #     b0 = 0,
  #     B0 = 1e1,
  #     sigma.mu = 1e1,
  #     sigma.var = 1e2,
  #     mcmc = 1e5
  #   )
  # write_rds(saida3_MCMCregr, "saida3_MCMCregr.Rds")
  
  modelo3 <- 
"
model {
  # observações
  for (i in 1:N) {
    Price_euros[i] ~
      dnorm(
        alpha +
        beta[1]  * Company[i] +
        beta[2]  * TypeName[i] +
        beta[3]  * Inches[i] +
        beta[4]  * OpSys[i] +
        beta[5]  * PPI[i] +
        beta[6]  * Touchscreen[i] +
        beta[7]  * FreqCPU[i] +
        beta[8]  * CPUMaker[i] +
        beta[9]  * GPUMaker[i] +
        beta[10] * Weight[i] +
        beta[11] * Ram[i] +
        beta[12] * HDD[i] +
        beta[13] * SSD[i] +
        beta[14] * Flash[i],
        sigma2)
  }
  # parâmetros
  alpha ~ dnorm(0, 1e2)
  for(j in 1:14) {
    beta[j] ~ dnorm(0, 1e2)
  }
  sigma2 ~ dchisqr(1e2)
}
"

dados3 <- 
  with(
    dataset3,
    list(
      N = nrow(dataset3),
      Price_euros = Price_euros,
      Company = Company,
      TypeName = TypeName,
      Inches = Inches,
      OpSys = OpSys,
      PPI = PPI,
      Touchscreen = Touchscreen +0,
      FreqCPU = FreqCPU,
      CPUMaker = CPUMaker,
      GPUMaker = GPUMaker,
      Weight = Weight,
      Ram = Ram,
      HDD = HDD,
      SSD = SSD,
      Flash = Flash
    )
  )

saida3_runjags <- 
  runjags::run.jags(
    model = modelo3,
    data = dados3,
    n.chains = 3, 
    inits = 
      function() {
        list(
          alpha = rnorm(1, 0, 1e2),
          beta = rnorm(14, 0, 1e2),
          sigma2 = rchisq(1, 1e2)
        )
      },
    monitor = c("alpha", "beta", "sigma2"),
    sample = 1e4
  )
  saida3_runjags
  
  # write_rds(saida3_MCMCregr, "saida3_MCMCregr.Rds")
  write_rds(saida3_runjags, "saida3_runjags.Rds")
}
```



## O que esses dados revelam?

***AQUI:*** análise da saída 



<!-- # Exemplo 4: nível maaaarromeno *hard* -->
<!-- Seria um modelo de regressão multi-nível, mas não deu tempo -->
<!-- ### Contexto -->
<!--   -  -->
<!--   - fonte: <https://???> -->
<!-- ### Necessidade de Informação -->
<!--   - a -->
<!--   - a -->
<!-- ## Dados Observados -->
<!-- ```{r carrega_dataset4} -->
<!-- if (file.exists("dataset4.Rds")) { -->
<!--   dataset4 <- read_rds("dataset4.Rds") -->
<!-- } else { -->
<!--   dataset4 <- read_csv("conjuntos de dados/???.csv") -->
<!--   write_rds(dataset4, "dataset4.Rds") -->
<!-- } -->
<!-- head(dataset4) %>% -->
<!--   kable("pandoc") -->
<!-- ``` -->
<!-- ## um método que pode ser empregado no problema -->
<!-- - com Estatística Clássica, é possível tentar usar modelagem de equações estruturais (SEM) -->
<!-- - com Estatística Bayesiano, é possível usar um modelo hierárquico multinível -->
<!-- - com estatística clássica, seria uma ANOVA + teste de  -->
<!--   comparação múltipla -->
<!--   - preocupação com a variância ser conhecida ou não, ser a mesma entre os  -->
<!--     grupos ou não -->
<!--   - às vezes, precisa apelar para testes assintóticos mesmo com amostras de  -->
<!--     tamanho moderado -->
<!--   - sem essas preocupações nos modelos hierárquicos -->
<!-- ## O que esses dados revelam? -->
<!-- ***AQUI:*** análise da saída  -->



# O que é Estatística Bayesiana?

## O que é Estatística Bayesiana?

Respondendo de uma forma enganadoramente simples, *Estatística Bayesiana* é uma 
forma lógica e quantitativamente coerente de decidir em que escolher acreditar 
ou escolher como agir em face aos dados observados

- Porquê "enganadoramente simples"?
  - É o que vamos ver nos próximos 5 *slides* e também nas próximas 5 *lives*



# As Próximas *Lives*

## As Próximas *Lives*

  
- a partir de um estado inicial de baixo conhecimento a respeito do fenômeno, 
  assumir uma crença difusa a seu respeito, coletar observações e atualizar 
  a crença de forma coerente em face ao que tiver sido observado

- essa escolha racional de crença ou expectativa sobre a realidade será 
  caracterizada quantitativamente na forma de *Probabilidade*, 
  tema da nossa **2^a^ _live_**



## As Próximas *Lives*

- mais detalhadamente: 
  - crença inicial (chamada *probabilidade a priori*)
    - anterior à coleta dos dados
    - vaga, difusa, imatura e incerta
  - crença atualizada pelos dados (chamada *probabilidade a posteriori*)
    - posterior à coleta dos dados
    - menos vaga, mais concentrada, mais madura e menos incerta
- esse processo de atualização da crença em função dos dados observados será
  realizado através de um mecanismo chamado *Teorema de Bayes*,
  tema da nossa **3^a^ _live_**



## As Próximas *Lives*
  
- de posse dessa crença final, é possível começar a responder a necessidade
  de informação sobre a realidade; mas é preciso antes saber caracterizar
  quantitativamente o tipo de necessidade de informação para usar essa crença;
  é aqui que entram a *Teoria da Decisão* e a *Inferência Bayesiana*,
  temas da nossa **4^a^ _live_**



## As Próximas *Lives*
  
- exceto em raras situações triviais, não será possível encontrar uma solução 
  analítica com aplicação de fórmulas matemáticas explícitas nos dados, 
  de modo que é preciso usar outra forma de calcular as respostas 
  às necessidades de informações; nesse ponto, falaremos dos métodos 
  computacionais que permitirão chegar às respostas, 
  o que será o tema da **5^a^ _live_**



## As Próximas *Lives*

- por fim, na nossa **6^a^ e última _live_**, retomaremos os 3 exemplos 
  desta 1^a^ *live* e vamos realizar a análise completa para cada um:
  - modelar os dados a partir do contexto e necessidade de informação
    apresentados
  - usar os programas R e JAGS para encontrar a resposta Bayesiana
  - levar de volta essa resposta ao contexto original, interpretando-a
