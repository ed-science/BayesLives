---
title: "_Bayes Lives_"
subtitle: |
    Série de _Lives_ de _Introdução às Bases da Estatística Bayesiana_ \
    _Live_ 1/6: 
      Apresentando a Estatística Bayesiana
author: |
    Prof. Dr. Marcelo Ventura Freire (EACH/USP)
    <https://github.com/zyxdef/BayesLives>
date: "16/03/2020"
output: 
  beamer_presentation:
      # keep_tex: yes
      keep_tex: no
header-includes:
  - \usepackage{enumitem}
  - \usepackage{tikzsymbols}
  - \setlistdepth{20}
  - \renewlist{itemize}{itemize}{20}
  - \renewlist{enumerate}{enumerate}{20}
  - \setlist[itemize]{label=$\cdot$}
  - \setlist[itemize,1]{label=*}
  - \setlist[itemize,2]{label=\textbullet}
  - \setlist[itemize,3]{label=--}
  - \setlist[itemize,4]{label=$\cdot$}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::knit_hooks$set(mysize = function(before, options, envir) {
  if (before) {
    return(options$size)
  } else {
    return("\\normalsize")
  }
})
knitr::opts_chunk$set(mysize = TRUE, size = "\\tiny")
options(omitlatexcom = T)
library(tidyverse)
library(kableExtra)
library(rjags)
library(runjags)
library(R2jags)
library(MCMCvis)
`%!in%` <- negate(`%in%`)
```

## Apresentação

***FAZER AQUI A APRESENTAÇÃO E DIZER QUEM SOU EU***

## Objetivos desta série de _lives_

O objetivos desta série de 6 _lives_ é dar uma visão panorâmica àquilo que dá a 
base, que dá o fundamento à Estatística Bayesiana, mas sem se pretender ser um
tutorial de uso e nem um curso teórico, pois não disporíamos de tempo o suficiente
para nenhum dos dois.

- O tutorial fica para a próxima série. $\Winkey$

- O repositório deste material está em <https://github.com/zyxdef/BayesLives>


# Exemplos de aplicação

## **PRÉ-ROTEIRIZAÇÃO** $\longrightarrow$ **Lembrar de tirar daqui**

Apresentação de 3 exemplos que motivarão e serão usados para ilustrar as _lives_ 
seguintes. 

- para cada exemplo, apresentaremos uma situação em que é preciso apresentar 
  - informação sobre o contexto da situação
    - afinal, toda análise é estritamente condicionada no contexto de onde 
      seus dados vieram
    - quais conceitos e definições devem ser usados?
    - quais pressuposições podem ser assumidas a respeito 
      - do que observamos?
      - do que *não* observamos?
    - qual é a natureza dos dados a serem trabalhados?
      - importa como, quando e em que ordem eles foram coletados?
      - se sim, quais são as respostas a essas perguntas?
    - em suma, não se faz análise em um vácuo de contexto (viu, ML e IA)

---

- para cada exemplo, apresentaremos uma situação em que é preciso apresentar 
  - qual é a necessidade de informação?
    - algum aspecto essa situação é desconhecida
    - quem precisa dessa informação?
    - de qual informação essa pessoa precisa?
    - qual o nível de detalhamento é necessário?
  - dados observados
    - apresentados parcial ou totalmente, em forma tabular 
  - nome do método bayesiano adequado para lidar com o problema
  - conclusão obtida para a necessidade de informação com a aplicação 
    desse método nesses dados

---

- idealmente, os exemplos terão grau crescente de complexidade 
  - simprão, simples e médio ?  
  - sem difícil; nada de modelos hierárquicos ou de BSEM
- idealmente, serão exemplos vindos de áreas distintas
  - ?? saúde pública
  - ?? marketing
  - ?? engenharia
- idealmente, os métodos cobrirão tipos diferentes de dados
  - respostas dummy,contagem e contínua
  - regressoras categóricas e quantitativas



# Exemplo 1: nível *very easy*

## Exemplo 1: nível *very easy*

- contexto da situação
  - teste A/B referente a conversões em uma *landing page*
- necessidade de informação
  - mudar um aspecto específico da *landing page* modifica a chance de o botão 
    de contratação do serviço ser clicado?
    - se sim, qual é a direção da mudança? Aumenta ou diminui a chance?
  - métrica de performance
   - conversão: quantos usuários clicaram no botão de contratação do serviço



## Exemplo 1: nível *very easy*

- dados observados
  - conjunto de dados do Kaggle
    - <https://www.kaggle.com/zhangluyuan/ab-testing>

```{r exemplo1, include=FALSE}
dataset1 <- read_csv("conjuntos de dados/ab_data.csv")
head(dataset1)
```



## Exemplo 1: nível *very easy*

- dados observados
  - `r ncol(dataset1)` colunas e `r nrow(dataset1)` linhas
  - colunas
    - `r colnames(dataset1)[1]`: identificação do usuário
    - `r colnames(dataset1)[2]`: data e hora do acesso à *landing page*
    - `r colnames(dataset1)[3]`: grupo a que atribuído o acesso, o qual foi 
      aleatorizado no momento do acesso à *landing page*
      - grupo controle *vs* grupo tratamento
    - `r colnames(dataset1)[4]`: qual página foi acessada
      - `old_page` *vs* `new_page`
    - `r colnames(dataset1)[5]`: conversão em venda (== clicou no botão mágico)
      - 0 == não *vs* 1 == sim



## Exemplo 1: nível *very easy*

Mas cuidado: parece que `r colnames(dataset1)[3]` e `r colnames(dataset1)[4]` 
são a mesma coisa, mas não são. Os respondentes foram separados em dois grupos

```{r tab_dataset1}
dataset1 %<>% group_by(user_id) %>% mutate(acessos = n()) %>% ungroup()
dataset1 %>% filter(acessos == 1) %>% with(table(group, landing_page)) %>% kable("pandoc")
dataset1 %>% filter(acessos > 1) %>% with(table(group, landing_page)) %>% kable("pandoc")
dataset1 %<>% filter(acessos == 1) %>% select(-acessos, -landing_page)
```



## Exemplo 1: nível *very easy*

Método adequado para lidar com o problema

1) verificar se a probabilidade de conversão é igual nos dois grupos
  a) se for diferente, determinar qual *landing page* tem maior probabilidade 
    de conversão
3) alternativamente, posso querer testar mais direcionadamente se a nova 
  *landing page* é melhor ou não que a anterior
  a) se sim, em quanto é maior?
2) alternativamente, posso só querer estimar a diferença de probabilidade de 
  conversão em função da diferença entre as versões nova e a antiga da 
  *landing page*, sem nenhuma direção preferencial
  a) qual é o valor mais provável dessa diferença?
  b) qual é a faixa de valores mais provável dessa diferença?



## Exemplo 1: nível *very easy*

O que esses dados revelam?

```{r prepara_1}
modelo1 <- 
"# comparando as probabilidades de duas binomiais
model{
  # modelo observado
      converted.control ~ dbin(p.control, N.control)
      converted.treatment ~ dbin(p.treatment, N.treatment)
  # modelo latente
      p.treatment <- ilogit(logit(p.control) + delta.logit.p)
      p.control ~ dbeta(1, 1)
      delta.logit.p ~ dnorm(0, 1)
  # medidas de interesse
      delta.p <- p.treatment - p.control
      pct.controle <- 100 * p.control
      pct.tratamento <- 100 * p.treatment
      delta.pct <- pct.tratamento - pct.controle
}"

# write_lines(modelo1, path = "modelo1.bugs")

dados1 <- 
  dataset1 %>% 
  group_by(group) %>% 
  summarise(
    converted = sum(converted),
    N = n()
  ) %>% 
  with(
    list(
      converted.control = converted[1],
      N.control = N[1],
      converted.treatment = converted[2],
      N.treatment = N[2]
    )
  )

inits1 <-
  list(
    list(p.control = .3, delta.logit.p =  0),
    list(p.control = .5, delta.logit.p = -1),
    list(p.control = .7, delta.logit.p = +1)
  )
```

```{r runjags_1}
runjags.options(mode.continuous = T)
saida1.runjags <- 
  runjags::run.jags(
    model = modelo1, 
    data = dados1, 
    inits = inits1, 
    n.chains = 3, 
    monitor =
      c(
        "p.control", 
        "p.treatment", 
        "delta.logit.p", 
        "delta.p",
        "pct.controle",
        "pct.tratamento",
        "delta.pct"
      ),
    sample = 1e5
  )
saida1.runjags
saida1.runjags %>% plot()
```




# Exemplo 2: nível *easy*

- contexto da situação:
  - avaliar a eficiência de 4 dietas de crescimento para criadouro de frango
  - fonte: `help(ChickWeight)` no R
- necessidade de informação:
  - há diferença sistemática entre os resultados das quatro dietas?
  - se houver, qual é a diferença de crescimento entre as dietas? 
  - como elas são comparáveis entre sí?
  - qual dieta é melhor? 
  - qual crescimento podemos esperar para um frango submetido à melhor dieta?

---

```{r dados_exemplo_2a, include=FALSE}
Granja <- 
  ChickWeight %>% 
  as.data.frame() %>% 
  filter(Time %in% c(0, 18)) %>%
  select(Chick, Diet, Time, weight) %>% 
  mutate(Chick = Chick %>% as.character() %>% as_factor()) %>% 
  pivot_wider(
    names_from = Time, 
    names_prefix = "Weight",
    values_from = weight
  ) %>% 
  na.exclude() %>% 
  mutate(PctGain = 100*(Weight18 - Weight0)/Weight0)
```

- Dados observados

```{r dados_exemplo_2b, results='asis', echo=FALSE}
Granja %>%
  mutate(PctGain = PctGain %>% round(2)) %>%
  head(30) %>% 
  Hmisc::latex(file = "", size = "tiny", multicol = T, rowname = NULL)
```

---

- Dados observados

```{r dados_exemplo_2c}
# knitr::asis_output("\\footnotesize")
Granja %>% select(-Chick) %>% str()
Granja %>% select(-Chick) %>% summary()
# knitr::asis_output("\\normalsize")
```

---

- método adequado para lidar com o problema
  - comparação entre médias dos quatros grupos
  - com Estatística Bayesiana, será um modelo hierárquico
  - se você entende de Estatística Clássica, seria uma ANOVA + teste de 
    comparação múltipla
    - preocupação com a variância ser conhecida ou não, ser a mesma entre os 
      grupos ou não
    - às vezes, precisa apelar para testes assintóticos mesmo com amostras de 
      tamanho moderado
    - sem essas preocupações nos modelos hierárquicos
- conclusão obtida



## Exemplo 3: nível *moderate*

- contexto da situação
  - precificação de modelos de laptops
  - fonte: <https://www.kaggle.com/ionaskel/laptop-prices>
- necessidade de informação
  - quais fatores são mais influentes na definição de preço? Não o *custo*, mas 
    sim o *preço*
  - é possível montar um modelo de precificação para um novo modelo de laptop em 
    termos das características que o modelo terá? qual seria uma faixa plausível 
    de valores para se propor?
- dados observados

```{r}
dados3 <- 
  readr::read_csv("conjuntos de dados/laptops.csv")
head(dados3) %>% 
  kable("pandoc")
```


- método adequado para lidar com o problema
  - modelo de regressão: uma variável resposta contínua e várias regressoras
- conclusão obtida


## Exemplo 4: nível *hard* -- nosso modelo de cognição musical

- contexto da situação
  - como lidamos com material como melodias?
  - ***VER MAIS NO RELATÓRIO DA FAPESP***
  - variáveis observáveis e variáveis latentes ligando as variáveis observáveis
  - diversos domínios não observáveis diretamente (variáveis latentes):
    - produção vocal
    - percepção auditiva
    - integração sensório-motora
    - memória operacional (working memory)
  - coleta de dados (variáveis observáveis)
    - tanto com instrumentos já consolidados como com instrumentos desenvolvidos 
      na pesquisa
    - escalas ordinais, dados de contagem e medidas contínuas
- necessidade de informação
  - o grau de habilidade de cada respondente em cada domínio em função das suas
    respostas no conjunto de instrumentos aplicados
  - o grau de influência de cada domínio em cada instrumento separadamente
  - avaliação da adequação dos instrumentos propostos
- dados observados
- método adequado para lidar com o problema
  - modelo hierárquico Bayesiano com modelagens diferentes para cada instrumento 
    em função do tipo de variáveis que observou
  - mas com as variáveis latentes por trás da associação (correlação) entre as
    variáveis dos diferentes instrumentos
- conclusão obtida
  - ***VER NO RELATÓRIO DA FAPESP***
- este último exemplo ilustra bem o potencial de utilização dos métodos Bayesianos 
  em contexto complicados de abordar 



## O que é Estatística Bayesiana?

Respondendo de uma forma enganadoramente simples, _Estatística Bayesiana_ é uma 
forma lógica e quantitativamente coerente de decidir em que escolher acreditar 
ou escolher como agir em face aos dados observados

- Porquê "enganadoramente simples"?
  - É o que vamos ver nos próximos 5 _slides_ e também nas próximas 5 *lives*

---
  
- a partir de um estado inicial de baixo conhecimento a respeito do fenômeno, 
  assumir uma crença difusa a seu respeito, coletar observações e atualizar 
  a crença de forma coerente em face ao que tiver sido observado
- essa escolha racional de crença ou expectativa sobre a realidade será 
  caracterizada quantitativamente na forma de *Probabilidade*, 
  tema da nossa **2^a^ _live_**

---

- mais detalhadamente: 
  - crença inicial (chamada *probabilidade a priori*)
    - anterior à coleta dos dados
    - vaga, difusa, imatura e incerta
  - crença atualizada pelos dados (chamada *probabilidade a posteriori*)
    - posterior à coleta dos dados
    - menos vaga, mais concentrada, mais madura e menos incerta
- esse processo de atualização da crença em função dos dados observados será
  realizado através de um mecanismo chamado _Teorema de Bayes_,
  tema da nossa **3^a^ _live_**
  
---
  
- de posse dessa crença final, é possível começar a responder a necessidade
  de informação sobre a realidade; mas é preciso antes saber caracterizar
  quantitativamente o tipo de necessidade de informação para usar essa crença;
  é aqui que entram a _Teoria da Decisão_ e a _Inferência Bayesiana_,
  temas da nossa **4^a^ _live_**
  
---
  
- exceto em raras situações triviais, não será possível encontrar uma solução 
  analítica com aplicação de fórmulas matemáticas explícitas nos dados, 
  de modo que é preciso usar outra forma de calcular as respostas 
  às necessidades de informações; nesse ponto, falaremos dos métodos 
  computacionais que permitirão chegar às respostas, 
  o que será o tema da **5^a^ _live_**

---

- por fim, na nossa **6^a^ e última _live_**, retomaremos os 3 exemplos 
  desta 1^a^ _live_ e vamos realizar a análise completa para cada um:
  - modelar os dados a partir do contexto e necessidade de informação apresentados
  - usar os programas R e JAGS para encontrar a resposta Bayesiana
  - levar de volta essa resposta ao contexto original, interpretando-a
